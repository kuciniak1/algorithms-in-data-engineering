{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936e3b17-6e67-4337-b2fd-c439868d402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aab672b-d403-4b54-a3e4-82c7f53a110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rotate (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rotate(matrix)\n",
    "    return reverse(reverse(matrix, dims=1), dims=2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "045ac6c2-28fb-442f-935a-afe2124be2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convolution_2d_pad (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Convolution_2d_pad(input, kernel; bias=0., padding=false)\n",
    "    input_rows, input_columns = size(input)\n",
    "    kernel_height, kernel_width = size(kernel)\n",
    "\n",
    "    if padding\n",
    "        padded_input = zeros(Float32, input_rows + 2*kernel_height - 2, input_columns + 2*kernel_width - 2)\n",
    "        padded_input[kernel_height:end-kernel_height+1, kernel_width:end-kernel_width+1] .= input\n",
    "        input_rows, input_columns = size(padded_input)\n",
    "        input = padded_input\n",
    "    end\n",
    "\n",
    "    output_rows = input_rows - kernel_height + 1\n",
    "    output_columns = input_columns - kernel_width + 1\n",
    "    output = zeros(Float32, output_rows, output_columns)\n",
    "\n",
    "\n",
    "    for c in 1:output_columns\n",
    "        for r in 1:output_rows\n",
    "            patch = @view input[r:r+kernel_height-1, c:c+kernel_width-1]\n",
    "            output[r, c] = sum(patch .* kernel) + bias\n",
    "        end\n",
    "    end\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4173fe6-711d-4a85-8249-fea33f3b757f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Convolution_2d (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Convolution_2d(input, kernel; bias=0.)\n",
    "    input_rows, input_columns = size(input)\n",
    "    kernel_height, kernel_width = size(kernel)\n",
    "\n",
    "    output_rows = input_rows - kernel_height + 1\n",
    "    output_columns = input_columns - kernel_width + 1\n",
    "    output = zeros(Float32, output_rows, output_columns)\n",
    "\n",
    "\n",
    "    for c in 1:output_columns\n",
    "        for r in 1:output_rows\n",
    "            patch = @view input[r:r+kernel_height-1, c:c+kernel_width-1]\n",
    "            output[r, c] = sum(patch .* kernel) + bias\n",
    "        end\n",
    "    end\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787b5c25-4636-4b63-9fa6-7f43de0b33d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv_backward_v1 (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Conv_backward_v1( input, weights, bias, gradient)\n",
    "    input_height, input_width, input_channels = size(input)\n",
    "    output_height, output_width, output_channels = size(gradient)\n",
    "    kernel_height, kernel_width, _, _ = size(weights)\n",
    "    \n",
    "    \n",
    "    grad_input = zeros(Float32, size(input))\n",
    "    for k in 1:input_channels\n",
    "        for c in 1:output_channels\n",
    "            grad_input[:, :, k] += Convolution_2d_pad(weights[:, :, k, c], gradient[:, :, c]; padding=true)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    grad_weights = zeros(Float32, size(weights))\n",
    "    for k in 1:input_channels\n",
    "        for c in 1:output_channels\n",
    "            grad_weights[:, :, k, c] += Convolution_2d(input[:, :, k], gradient[:, :, c])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    grad_bias = reshape(sum(gradient, dims=(1,2,4)), :)\n",
    "    \n",
    "    return grad_input, grad_weights, grad_bias\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70169f26-159a-4bcd-906b-e57371b9d210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv_backward_v2 (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Conv_backward_v2(input, weights, bias, gradient)\n",
    "    input_height, input_width, input_channels = size(input)\n",
    "    output_height, output_width, output_channels = size(gradient)\n",
    "    kernel_height, kernel_width, _, _ = size(weights)\n",
    "    \n",
    "    \n",
    "    grad_input = zeros(Float32, size(input))\n",
    "    grad_weights = zeros(Float32, size(weights))\n",
    "    \n",
    "    tmp_weights = zeros(Float32, kernel_height, kernel_width)\n",
    "    tmp_input = zeros(Float32, input_height, input_width)\n",
    "    tmp_gradient = zeros(Float32, output_height, output_width)\n",
    "    \n",
    "    for k in 1:input_channels\n",
    "        for c in 1:output_channels\n",
    "            tmp_weights .= @views weights[:, :, k, c]\n",
    "            tmp_gradient .= @views gradient[:, :, c]\n",
    "            grad_input[:, :, k] .+= Convolution_2d_pad(tmp_weights, rotate(tmp_gradient); padding=true)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    \n",
    "    for k in 1:input_channels\n",
    "        for c in 1:output_channels\n",
    "            tmp_input .= @views input[:, :, k]\n",
    "            tmp_gradient .= @views gradient[:, :, c]\n",
    "            grad_weights[:, :, k, c] += Convolution_2d(tmp_input, tmp_gradient)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    grad_bias = reshape(sum(gradient, dims=(1,2,4)), :)\n",
    "    \n",
    "    return grad_input, grad_weights, grad_bias\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e572997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv_backward_v3 (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Conv_backward_v3( input, weights, bias, gradient)\n",
    "    input_height, input_width, input_channels = size(input)\n",
    "    output_height, output_width, output_channels = size(gradient)\n",
    "    kernel_height, kernel_width, _, _ = size(weights)\n",
    "    \n",
    "    grad_input = zeros(Float32, size(input))\n",
    "    grad_weights = zeros(Float32, size(weights))\n",
    "    \n",
    "    tmp_weights = zeros(Float32, kernel_height, kernel_width)\n",
    "    tmp_input = zeros(Float32, input_height, input_width)\n",
    "    tmp_gradient = zeros(Float32, output_height, output_width)\n",
    "    \n",
    "    for k in 1:input_channels\n",
    "        for c in 1:output_channels\n",
    "            tmp_weights .= @views weights[:, :, k, c]\n",
    "            tmp_gradient .= @views gradient[:, :, c]\n",
    "            for i = 1:output_height\n",
    "                for j = 1:output_width\n",
    "                    grad_input[i:i+kernel_height-1, j:j+kernel_width-1, k] .+= (tmp_weights .* tmp_gradient[i,j]);\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for k in 1:input_channels\n",
    "        for c in 1:output_channels\n",
    "            tmp_input .= @views input[:, :, k]\n",
    "            tmp_gradient .= @views gradient[:, :, c]\n",
    "            grad_weights[:, :, k, c] += Convolution_2d(tmp_input, tmp_gradient)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    grad_bias = reshape(sum(gradient, dims=(1,2,4)), :)\n",
    "    \n",
    "    return grad_input, grad_weights, grad_bias\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a211139-dd26-485b-ba75-21c02c0ad524",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = rand(28, 28, 1);\n",
    "weights = rand(3, 3, 1, 6);\n",
    "bias = rand(Float32, 6);\n",
    "gradient = rand(26, 26, 6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a279f768-4514-4ba9-80a4-13aaace78226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 722 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m4.719 ms\u001b[22m\u001b[39m … \u001b[35m12.454 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 51.26%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m7.562 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m34.68%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m6.920 ms\u001b[22m\u001b[39m ± \u001b[32m 1.489 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m24.76% ± 17.77%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m▅\u001b[39m█\u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[34m▃\u001b[39m\u001b[39m▂\u001b[39m▂\u001b[39m▄\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m▃\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[32m▁\u001b[39m\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▇\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▃\n",
       "  4.72 ms\u001b[90m        Histogram: frequency by time\u001b[39m          10 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m25.79 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m4842\u001b[39m."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark Conv_backward_v1(input, weights, bias, gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17651caf-f1c5-46c0-b074-53f96ddd1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark Conv_backward_v2(input, weights, bias, gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbb4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark Conv_backward_v3(input, weights, bias, gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb067e2-2701-476e-b629-f194cd2f4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark Conv_backward_v3(input, weights, bias, gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc272c-9ddd-46f3-a879-e3aa8cdce315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
